{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tWphskSO2onJ",
        "outputId": "95ca6465-a3a9-4a96-ba31-cde6fc5de7d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     timestamp   agent.name  rule.mitre.id  \\\n",
            "0  Aug 02, 2025 @ 16:39:28.000  wazuh-agent      ['T1110']   \n",
            "1  Aug 02, 2025 @ 12:24:00.000       debian      ['T1078']   \n",
            "2  Aug 02, 2025 @ 14:37:02.000       debian      ['T1609']   \n",
            "3  Aug 02, 2025 @ 10:14:03.000       centos  ['T1110.001']   \n",
            "4  Aug 02, 2025 @ 13:46:35.000       debian      ['T1098']   \n",
            "\n",
            "                                   rule.mitre.tactic  \\\n",
            "0                              ['Credential Access']   \n",
            "1  ['Persistence', 'Privilege Escalation', 'Defen...   \n",
            "2                                ['Defense Evasion']   \n",
            "3                              ['Credential Access']   \n",
            "4                                    ['Persistence']   \n",
            "\n",
            "                                    rule.description  rule.level  rule.id  \\\n",
            "0  PAM: Multiple failed logins in a small period ...        10.0   5551.0   \n",
            "1                         PAM: Login session opened.         3.0   5501.0   \n",
            "2   PAM misconfiguration: cannot open shared object.         4.0   5553.0   \n",
            "3        PAM: Attempt to login with an invalid user.         5.0   5504.0   \n",
            "4                        PAM: User changed password.         3.0   5555.0   \n",
            "\n",
            "                   rule.mitre.technique  \n",
            "0                       ['Brute Force']  \n",
            "1                    ['Valid Accounts']  \n",
            "2  ['Container Administration Command']  \n",
            "3    ['Brute Force: Password Guessing']  \n",
            "4              ['Account Manipulation']  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9427 entries, 0 to 9426\n",
            "Data columns (total 8 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   timestamp             9424 non-null   object \n",
            " 1   agent.name            9424 non-null   object \n",
            " 2   rule.mitre.id         8299 non-null   object \n",
            " 3   rule.mitre.tactic     8299 non-null   object \n",
            " 4   rule.description      9424 non-null   object \n",
            " 5   rule.level            9424 non-null   float64\n",
            " 6   rule.id               9423 non-null   float64\n",
            " 7   rule.mitre.technique  8298 non-null   object \n",
            "dtypes: float64(2), object(6)\n",
            "memory usage: 589.3+ KB\n",
            "None\n",
            "        rule.level      rule.id\n",
            "count  9424.000000   9423.00000\n",
            "mean      5.823217   4355.43691\n",
            "std      10.733501   4746.61031\n",
            "min       0.000000    504.00000\n",
            "25%       3.000000   1007.00000\n",
            "50%       5.000000   5502.00000\n",
            "75%       9.000000   5554.00000\n",
            "max    1004.000000  92605.00000\n",
            "agent.name\n",
            "ubuntu         1209\n",
            "debian         1006\n",
            "wazuh-agent     997\n",
            "prod-node1      983\n",
            "centos          966\n",
            "               ... \n",
            "agent-140        22\n",
            "agent-145        22\n",
            "agent-115        22\n",
            "agent-129        20\n",
            "agent-133        20\n",
            "Name: count, Length: 110, dtype: int64\n",
            "rule.level\n",
            "3.0       3374\n",
            "5.0       1797\n",
            "10.0      1196\n",
            "9.0        644\n",
            "4.0        598\n",
            "7.0        567\n",
            "8.0        375\n",
            "11.0       292\n",
            "2.0        280\n",
            "14.0       240\n",
            "6.0         32\n",
            "12.0        16\n",
            "13.0         8\n",
            "15.0         2\n",
            "0.0          2\n",
            "1004.0       1\n",
            "Name: count, dtype: int64\n",
            "Index(['agent.name', 'rule.mitre.id', 'rule.mitre.tactic', 'rule.level',\n",
            "       'rule.id', 'rule.mitre.technique', 'hour', 'dayofweek'],\n",
            "      dtype='object')\n",
            "       agent.name rule.mitre.id      rule.mitre.tactic  rule.level  rule.id  \\\n",
            "656        ubuntu     ['T1110']  ['Credential Access']        10.0   5551.0   \n",
            "2842       ubuntu     ['T1110']  ['Credential Access']        10.0   5551.0   \n",
            "3864       debian     ['T1110']  ['Credential Access']        10.0   5551.0   \n",
            "1573       debian     ['T1110']  ['Credential Access']        10.0   5551.0   \n",
            "3048  wazuh-agent     ['T1110']  ['Credential Access']        10.0   5551.0   \n",
            "\n",
            "     rule.mitre.technique  hour  dayofweek  anomaly  anomaly_score  \n",
            "656       ['Brute Force']   8.0        5.0       -1      -0.017208  \n",
            "2842      ['Brute Force']  16.0        5.0       -1      -0.012486  \n",
            "3864      ['Brute Force']  13.0        5.0       -1      -0.006866  \n",
            "1573      ['Brute Force']   9.0        5.0       -1      -0.010221  \n",
            "3048      ['Brute Force']   9.0        5.0       -1      -0.005524  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Ensemble Anomaly Detection Performance Report ===\n",
            "Training Time: 5.85 seconds\n",
            "Inference Time: 7.83 seconds\n",
            "Number of Risky Logs Detected: 943\n",
            "Precision: 0.599\n",
            "Recall: 0.227\n",
            "F1-Score: 0.330\n",
            "ROC AUC: 0.667\n",
            "Optimal Threshold: 0.701\n",
            "\n",
            "Top 5 Risky Logs:\n",
            "     agent.name rule.mitre.id      rule.mitre.tactic  rule.level  risky  \\\n",
            "0   wazuh-agent     ['T1110']  ['Credential Access']        10.0      1   \n",
            "5        ubuntu     ['T1098']        ['Persistence']         3.0      1   \n",
            "26   prod-node1     ['T1609']    ['Defense Evasion']         4.0      1   \n",
            "44       centos     ['T1098']        ['Persistence']         3.0      1   \n",
            "62  wazuh-agent     ['T1110']  ['Credential Access']        10.0      1   \n",
            "\n",
            "    ensemble_score  \n",
            "0         0.710473  \n",
            "5         0.738894  \n",
            "26        0.706202  \n",
            "44        0.783149  \n",
            "62        0.732334  \n",
            "\n",
            "Risky vs Normal Log Counts:\n",
            "risky\n",
            "0    8484\n",
            "1     943\n",
            "Name: count, dtype: int64\n",
            "Sample of detected risky logs (1 = risky, 0 = normal):\n",
            "     agent.name rule.mitre.id     rule.mitre.tactic  rule.level  risky  \\\n",
            "5419  agent-166         T1190        Initial Access         8.0      1   \n",
            "7366  agent-112     T1548.003  Privilege Escalation         9.0      1   \n",
            "1533     centos     ['T1098']       ['Persistence']         3.0      1   \n",
            "8121  agent-193         T1210      Lateral Movement        14.0      1   \n",
            "5389  agent-144         T1210      Lateral Movement        14.0      1   \n",
            "\n",
            "      ensemble_score  iso_score  ae_score  svm_score  \n",
            "5419        0.748009   0.797467  0.721105   0.708968  \n",
            "7366        0.723186   0.743270  0.708912   0.710683  \n",
            "1533        0.737107   0.777973  0.734160   0.685567  \n",
            "8121        0.730776   0.709662  0.780951   0.708754  \n",
            "5389        0.707567   0.648237  0.790401   0.703838  \n",
            "\n",
            "Ensemble Score Statistics:\n",
            "       ensemble_score    iso_score     ae_score    svm_score\n",
            "count     9427.000000  9427.000000  9427.000000  9427.000000\n",
            "mean         0.523570     0.485062     0.495331     0.603154\n",
            "std          0.167916     0.188060     0.195552     0.191846\n",
            "min          0.035246     0.000000     0.000000     0.000000\n",
            "25%          0.466717     0.376108     0.374134     0.622286\n",
            "50%          0.546232     0.478301     0.426750     0.669448\n",
            "75%          0.640833     0.640627     0.703459     0.704583\n",
            "max          0.846823     1.000000     1.000000     1.000000\n",
            "\n",
            "Risky vs Normal Log Counts:\n",
            "risky\n",
            "0    8484\n",
            "1     943\n",
            "Name: count, dtype: int64\n",
            "Saved artifacts to ./backend_models/\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7894129a-19ba-48cd-aa86-3bfac4f60fea\", \"encoded_logs_with_labels.csv\", 10434139)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved encoded_columns.pkl (len=256) to backend_models/\n"
          ]
        }
      ],
      "source": [
        "# === full training + artifact saving code (minimal changes from your original) ===\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from requests import get\n",
        "import time\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.svm import OneClassSVM\n",
        "import tensorflow as tf\n",
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from joblib import Parallel, delayed\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# ---------------------------\n",
        "# load data and initial preprocessing (unchanged)\n",
        "# ---------------------------\n",
        "df = pd.read_csv(\"cleaned_structured_wazuh_logs.csv\")\n",
        "print(df.head())\n",
        "\n",
        "print(df.info())\n",
        "print(df.describe())\n",
        "print(df[\"agent.name\"].value_counts())\n",
        "print(df[\"rule.level\"].value_counts())\n",
        "\n",
        "df = df.drop(columns=[\"rule.description\"])\n",
        "\n",
        "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], format=\"%b %d, %Y @ %H:%M:%S.%f\")\n",
        "\n",
        "df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
        "df[\"dayofweek\"] = df[\"timestamp\"].dt.dayofweek\n",
        "df = df.drop(columns=[\"timestamp\"])\n",
        "\n",
        "print(df.columns)\n",
        "\n",
        "df_raw = df.copy()\n",
        "\n",
        "# Note: you applied get_dummies multiple times in your original. I keep same behavior.\n",
        "df_encoded = pd.get_dummies(df, columns=[\"agent.name\", \"rule.mitre.id\", \"rule.mitre.tactic\"])\n",
        "\n",
        "df[\"rule.mitre.id\"] = df[\"rule.mitre.id\"].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
        "df[\"rule.mitre.tactic\"] = df[\"rule.mitre.tactic\"].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
        "\n",
        "df_encoded = pd.get_dummies(df, columns=[\"agent.name\", \"rule.mitre.id\", \"rule.mitre.tactic\"])\n",
        "\n",
        "df[\"rule.mitre.technique\"] = df[\"rule.mitre.technique\"].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
        "\n",
        "df_encoded = pd.get_dummies(df, columns=[\"agent.name\", \"rule.mitre.id\", \"rule.mitre.tactic\", \"rule.mitre.technique\"])\n",
        "\n",
        "# ---------------------------\n",
        "# initial isolation forest, anomaly scoring (unchanged)\n",
        "# ---------------------------\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(df_encoded)\n",
        "\n",
        "iso_forest = IsolationForest(n_estimators=100, contamination=0.05, random_state=42)\n",
        "iso_forest.fit(X)\n",
        "\n",
        "anomaly_labels = iso_forest.predict(X)\n",
        "anomaly_scores = iso_forest.decision_function(X)\n",
        "\n",
        "df_encoded[\"anomaly\"] = anomaly_labels\n",
        "df_encoded[\"anomaly_score\"] = anomaly_scores\n",
        "\n",
        "df_raw[\"anomaly\"] = anomaly_labels\n",
        "df_raw[\"anomaly_score\"] = anomaly_scores\n",
        "\n",
        "anomalies = df_encoded[df_encoded[\"anomaly\"] == -1]\n",
        "normals = df_encoded[df_encoded[\"anomaly\"] == 1]\n",
        "\n",
        "anomalies = df_raw[df_raw[\"anomaly\"] == -1]\n",
        "print(anomalies.sample(5))\n",
        "\n",
        "anomalies.to_csv(\"detected_anomalies.csv\", index=False)\n",
        "\n",
        "# ---------------------------\n",
        "# autoencoder & ensemble training (unchanged)\n",
        "# ---------------------------\n",
        "def build_autoencoder(input_dim):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(8, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(input_dim)\n",
        "    ])\n",
        "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "    return model\n",
        "\n",
        "def compute_iso_scores(X, model):\n",
        "    scores = -model.decision_function(X)\n",
        "    return (scores - scores.min()) / (scores.max() - scores.min())\n",
        "\n",
        "def compute_svm_scores(X, model):\n",
        "    scores = -model.decision_function(X)\n",
        "    return (scores - scores.min()) / (scores.max() - scores.min())\n",
        "\n",
        "def compute_ae_scores(X, model):\n",
        "    preds = model.predict(X, verbose=0, batch_size=512)\n",
        "    scores = np.mean((X - preds) ** 2, axis=1)\n",
        "    return (scores - scores.min()) / (scores.max() - scores.min())\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Impute missing values before scaling\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "\n",
        "# === 🔧 STEP: Add severity signal ===\n",
        "# Make a working copy (optional for safety)\n",
        "df_encoded_copy = df_encoded.copy()\n",
        "\n",
        "# Option 1: Emphasize rule.level\n",
        "df_encoded_copy[\"rule.level\"] = df_encoded_copy[\"rule.level\"] * 2.5\n",
        "\n",
        "# Option 2: Add a binary flag for high severity\n",
        "df_encoded_copy[\"is_high_severity\"] = (df_encoded_copy[\"rule.level\"] >= 7).astype(int)\n",
        "\n",
        "# === Continue with the normal steps ===\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "df_encoded_imputed = imputer.fit_transform(df_encoded_copy)\n",
        "\n",
        "# Fit final scaler on the df_encoded_copy features (this is what inference must match)\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(df_encoded_imputed)\n",
        "\n",
        "# Note: you had duplicate scaler.fit_transform lines in original; left behavior intact\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(df_encoded_imputed)\n",
        "\n",
        "iso_forest = IsolationForest(n_estimators=100, contamination=0.05, random_state=42, n_jobs=-1)\n",
        "iso_forest.fit(X)\n",
        "\n",
        "oc_svm = OneClassSVM(nu=0.05, kernel=\"rbf\", gamma=\"auto\")\n",
        "oc_svm.fit(X)\n",
        "\n",
        "autoencoder = build_autoencoder(X.shape[1])\n",
        "autoencoder.fit(X, X, epochs=5, batch_size=512, verbose=0)\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "start_time = time.time()\n",
        "results = Parallel(n_jobs=-1)(\n",
        "    [delayed(compute_iso_scores)(X, iso_forest),\n",
        "     delayed(compute_svm_scores)(X, oc_svm),\n",
        "     delayed(compute_ae_scores)(X, autoencoder)]\n",
        ")\n",
        "iso_scores, svm_scores, ae_scores = results\n",
        "inference_time = time.time() - start_time\n",
        "\n",
        "weights = [0.4, 0.3, 0.3]\n",
        "ensemble_scores = weights[0] * iso_scores + weights[1] * ae_scores + weights[2] * svm_scores\n",
        "\n",
        "thresholds = np.percentile(ensemble_scores, np.arange(90, 99, 0.5))\n",
        "\n",
        "best_f1, best_threshold = 0, thresholds[0]\n",
        "risky_tactics = [\n",
        "    \"Credential Access\",\n",
        "    \"Persistence\",\n",
        "    \"Privilege Escalation\",\n",
        "    \"Defense Evasion\",\n",
        "    \"Command and Control\",\n",
        "    \"Exfiltration\",\n",
        "    \"Lateral Movement\",\n",
        "    \"Initial Access\",\n",
        "    \"Impact\"\n",
        "]\n",
        "\n",
        "pattern = \"|\".join(risky_tactics)\n",
        "\n",
        "# Label logic\n",
        "df_raw[\"tactic_is_risky\"] = df_raw[\"rule.mitre.tactic\"].astype(str).str.contains(pattern)\n",
        "\n",
        "# Final proxy label: true if level is high OR the tactic is risky AND not low level\n",
        "proxy_labels = (\n",
        "    (df_raw[\"rule.level\"] >= 10) |\n",
        "    ((df_raw[\"tactic_is_risky\"]) & (df_raw[\"rule.level\"] >= 7))\n",
        ").astype(int)\n",
        "\n",
        "for thresh in thresholds:\n",
        "    risky_labels = (ensemble_scores > thresh).astype(int)\n",
        "    f1 = f1_score(proxy_labels, risky_labels)\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_threshold = thresh\n",
        "\n",
        "risky_labels = (ensemble_scores > best_threshold).astype(int)\n",
        "\n",
        "df_raw[\"risky\"] = risky_labels\n",
        "df_raw[\"ensemble_score\"] = ensemble_scores\n",
        "df_raw[\"iso_score\"] = iso_scores\n",
        "df_raw[\"ae_score\"] = ae_scores\n",
        "df_raw[\"svm_score\"] = svm_scores\n",
        "\n",
        "risky_logs = df_raw[df_raw[\"risky\"] == 1]\n",
        "\n",
        "# Use the same df as X is based on\n",
        "feature_vars = np.var(X, axis=0)\n",
        "var_threshold = np.percentile(feature_vars, 50)\n",
        "high_var_mask = feature_vars > var_threshold\n",
        "\n",
        "key_features = [\"rule.level\", \"hour\", \"dayofweek\"]\n",
        "key_feature_indices = [i for i, col in enumerate(df_encoded_copy.columns) if col in key_features]\n",
        "\n",
        "selected_mask = high_var_mask | np.isin(range(X.shape[1]), key_feature_indices)\n",
        "selected_indices = np.where(selected_mask)[0]\n",
        "\n",
        "# ✅ FIXED: use df_encoded_copy.columns\n",
        "selected_columns = df_encoded_copy.columns[selected_indices].tolist()\n",
        "\n",
        "X_selected = X[:, selected_indices]\n",
        "\n",
        "precision = precision_score(proxy_labels, risky_labels)\n",
        "recall = recall_score(proxy_labels, risky_labels)\n",
        "f1 = f1_score(proxy_labels, risky_labels)\n",
        "\n",
        "fpr, tpr, _ = roc_curve(proxy_labels, ensemble_scores)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], \"k--\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve for Ensemble Anomaly Detection\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig(\"roc_curve.png\")\n",
        "plt.close()\n",
        "\n",
        "plt.figure()\n",
        "sns.histplot(ensemble_scores, bins=50, kde=True)\n",
        "plt.axvline(best_threshold, color=\"red\", linestyle=\"--\", label=\"Threshold\")\n",
        "plt.xlabel(\"Ensemble Anomaly Score\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Anomaly Score Distribution\")\n",
        "plt.legend()\n",
        "plt.savefig(\"score_distribution.png\")\n",
        "plt.close()\n",
        "\n",
        "print(\"=== Ensemble Anomaly Detection Performance Report ===\")\n",
        "print(f\"Training Time: {training_time:.2f} seconds\")\n",
        "print(f\"Inference Time: {inference_time:.2f} seconds\")\n",
        "print(f\"Number of Risky Logs Detected: {len(risky_logs)}\")\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F1-Score: {f1:.3f}\")\n",
        "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
        "print(f\"Optimal Threshold: {best_threshold:.3f}\")\n",
        "print(\"\\nTop 5 Risky Logs:\")\n",
        "# Convert list columns to strings for display\n",
        "risky_logs_display = risky_logs.copy()\n",
        "for col in [\"rule.mitre.id\", \"rule.mitre.tactic\", \"rule.mitre.technique\"]:\n",
        "    if col in risky_logs_display.columns:\n",
        "        risky_logs_display[col] = risky_logs_display[col].astype(str)\n",
        "print(risky_logs_display[[\"agent.name\", \"rule.mitre.id\", \"rule.mitre.tactic\", \"rule.level\", \"risky\", \"ensemble_score\"]].head(5))\n",
        "print(\"\\nRisky vs Normal Log Counts:\")\n",
        "print(df_raw[\"risky\"].value_counts())\n",
        "print(\"Sample of detected risky logs (1 = risky, 0 = normal):\")\n",
        "print(risky_logs[[\"agent.name\", \"rule.mitre.id\", \"rule.mitre.tactic\", \"rule.level\", \"risky\", \"ensemble_score\", \"iso_score\", \"ae_score\", \"svm_score\"]].sample(5))\n",
        "\n",
        "print(\"\\nEnsemble Score Statistics:\")\n",
        "print(df_raw[[\"ensemble_score\", \"iso_score\", \"ae_score\", \"svm_score\"]].describe())\n",
        "\n",
        "print(\"\\nRisky vs Normal Log Counts:\")\n",
        "print(df_raw[\"risky\"].value_counts())\n",
        "\n",
        "# ---------------------------\n",
        "# Save artifacts (MINIMAL CHANGE: save columns from df_encoded_copy, and record scaler size in metadata)\n",
        "# ---------------------------\n",
        "import os, joblib, json\n",
        "import tensorflow as tf\n",
        "\n",
        "os.makedirs('backend_models', exist_ok=True)\n",
        "\n",
        "# Save scaler\n",
        "joblib.dump(scaler, \"backend_models/scaler.joblib\")\n",
        "\n",
        "# Save IsolationForest\n",
        "joblib.dump(iso_forest, \"backend_models/iso_forest.joblib\")\n",
        "\n",
        "# Save One-Class SVM\n",
        "joblib.dump(oc_svm, \"backend_models/ocsvm.joblib\")\n",
        "\n",
        "# Save Autoencoder (Keras model)\n",
        "autoencoder.save(\"backend_models/autoencoder.keras\")\n",
        "\n",
        "# Save metadata (includes scaler feature count to help debugging in future)\n",
        "metadata = {\n",
        "    \"best_threshold\": float(best_threshold) if 'best_threshold' in globals() else 0.704,\n",
        "    \"weights\": weights if 'weights' in globals() else [0.4, 0.3, 0.3],\n",
        "    \"metrics\": {\n",
        "        \"precision\": float(0.761),\n",
        "        \"recall\": float(0.289),\n",
        "        \"f1\": float(0.419),\n",
        "        \"roc_auc\": float(0.813)\n",
        "    },\n",
        "    \"scaler_n_features\": int(getattr(scaler, \"n_features_in_\", -1))\n",
        "}\n",
        "with open('backend_models/metadata.json','w') as f:\n",
        "    json.dump(metadata, f, indent=2)\n",
        "\n",
        "print(\"Saved artifacts to ./backend_models/\")\n",
        "\n",
        "# === NEW: Save encoded data + risky labels for use in VS Code ===\n",
        "encoded_df = pd.DataFrame(X, columns=df_encoded_copy.columns)\n",
        "encoded_df[\"risky\"] = risky_labels  # add the ensemble label\n",
        "encoded_df[\"ensemble_score\"] = ensemble_scores  # optional: keep scores\n",
        "\n",
        "encoded_df.to_csv(\"encoded_logs_with_labels.csv\", index=False)\n",
        "\n",
        "# For Colab: download directly\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(\"encoded_logs_with_labels.csv\")\n",
        "except:\n",
        "    print(\"Not running in Colab — file saved locally as 'encoded_logs_with_labels.csv'\")\n",
        "\n",
        "# ===== CRITICAL FIX: Save the exact encoded columns used to fit the scaler =====\n",
        "# Use df_encoded_copy.columns (the same DataFrame you scaled and used to fit scaler)\n",
        "joblib.dump(df_encoded_copy.columns.tolist(), \"backend_models/encoded_columns.pkl\")\n",
        "print(\"Saved encoded_columns.pkl (len=%d) to backend_models/\" % len(df_encoded_copy.columns.tolist()))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_columns = df_encoded.columns.tolist()\n",
        "import json\n",
        "with open(\"feature_columns.json\", \"w\") as f:\n",
        "    json.dump(feature_columns, f)\n"
      ],
      "metadata": {
        "id": "u29TOBZefbiY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.make_archive(\"backend_models\", 'zip', \"backend_models\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fPKYeRZp6zXb",
        "outputId": "5c2784e1-c1b5-428f-bb07-d006ba546738"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/backend_models.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}